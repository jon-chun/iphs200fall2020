{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proj_iphs200fall2020_max_polling_knox_co_20201210.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/programminghumanity/iphs200fall2020/blob/main/proj_iphs200fall2020_max_polling_knox_co_20201210.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cipxJrM74w41"
      },
      "source": [
        "# **Step 0. Setup Environment, Download Files and Outline Project**\n",
        "\n",
        "Note:\n",
        "\n",
        "* There are two code cells that require input before continuing automatic execution (#2 gdrive auth) and (#7 unzip [A]ll)\n",
        "* The DataFrame knox_2006_addr_df contains the address and computed (long, lat) coordinates because only 2006 dataset has address info\n",
        "* The DataFrame knox_2006_2012_df contains columns that track the changes in voter registration over the period 2006 to 2012\n",
        "* More polling stations were added beween 2006 and 2012 but we don't have any address information on them\n",
        "* Rows/records on polling addresses are incomplete in the 2006 dataset\n",
        "* Some data cells are blank or have bad data in the original datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2LGR5N_zwU2"
      },
      "source": [
        "%load_ext google.colab.data_table\n",
        "\n",
        "# Allows interactive filtering/scrolling of DataFrame\n",
        "# %unload_ext google.colab.data_table # To unload interative DataFrame widget\n",
        "# Ref: https://colab.research.google.com/notebooks/data_table.ipynb#scrollTo=JgBtx0xFFv_i "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jU8hYsAAXvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732fca66-16cd-4154-f6c4-d31a447643d3"
      },
      "source": [
        "# GIVE AUTORIZATION\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sPAHRZfKEku",
        "outputId": "2bea954e-96c3-4a56-e0c2-967038312194"
      },
      "source": [
        "#  customize to your working directory\n",
        "\n",
        "%cd ./MyDrive/courses/2020f_iphs200_programming_humanity/code/knox_vote/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/courses/2020f_iphs200_programming_humanity/code/knox_vote\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWcZnGhHBWkh"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKqPGitYAjX3"
      },
      "source": [
        "!wget https://www.co.knox.oh.us/taxmap/FilestoDownload/vote_precincts.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfEiAwpVAja7"
      },
      "source": [
        "!ls *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMYw38t0Cv5p"
      },
      "source": [
        "# MANUALLY Click on promt and enter [A]ll option in text input below\n",
        "\n",
        "!unzip vote_precincts.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX0xeldsA2sc"
      },
      "source": [
        "!ls vote_precincts.*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOcXaq3HBrgC"
      },
      "source": [
        "# Make sure we have the source polling *.xls datafile\n",
        "\n",
        "!ls knox*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCRBkMoCPQMi"
      },
      "source": [
        "url_file = 'knox_co_oh_polling_addr_2006_2012_20201210.xlsx'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4uZRVlABlm0"
      },
      "source": [
        "## **Step 0 (a) GeoPandas for Knox County Ohio**\n",
        "\n",
        "References:\n",
        "* (Data Sources) https://www.co.knox.oh.us/index.php/files-to-download\n",
        "* (DataCamp) https://campus.datacamp.com/courses/visualizing-geospatial-data-in-python/\n",
        "* (Tutorial) https://towardsdatascience.com/geopandas-101-plot-any-data-with-a-latitude-and-longitude-on-a-map-98e01944b972\n",
        "* (w/github) https://github.com/rylativity/identifying_wnv_locations-raw_repo- (20180924 18s)\n",
        "\n",
        "```\n",
        "I've updated the colab notebook we found and corrected a few typos, etc. You can see it at this link with the voting precints mapped in color:\n",
        "https://colab.research.google.com/drive/1iVyX6dIpoBDisjW2nb_a-GN2V-uJ7Y2p?usp=sharing\n",
        "At the top of this file I list references you can use to expand upon this. In particular, the first two chapters of the DataCamp on GeoPandas shows how you can sjoin several geopandas dataframes like sql joins on different database tables.\n",
        "One idea is for you to generate two more *.shp files which plot the (longitude, latitude) coordinates forÂ \n",
        "a) current polling stationsb) potential better/more central/easier to access polling stations.\n",
        "You can use this website to get the (lng, lat) geo coordinates for any existing or proposed polling address from sites like this:\n",
        "https://www.latlong.net/convert-address-to-lat-long.html\n",
        "You would then manually compile a *.shp file using Point datatype as explained in DataCamp.\n",
        "If you could get some data on population centers or ease of access routes/traffic flows that we discussed today, you could do some interesting work like suggesting more accessible polling locations:\n",
        "https://medium.com/@sumit.arora/plotting-weighted-mean-population-centroids-on-a-country-map-22da408c1397https://geopandas.org/geometric_manipulations.html\n",
        "Check these resources out and let me know if you have more questions,\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLUwSeyY19UG"
      },
      "source": [
        "![alt text](https://vignette.wikia.nocookie.net/genealogy/images/e/e7/Map_of_Knox_County_Ohio_With_Municipal_and_Township_Labels.PNG/revision/latest?cb=20071118214504)\n",
        "\n",
        "## **Step 0. (b) How to Analyze Geographic Data in Shapefiles**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03mqgxaU3EZX"
      },
      "source": [
        "From empty Dorrito bags and fast food cups lining the curb, to plastic bags stuck in trees, litter mars too many L.A. neighborhoods. In response, in 2016 Mayor Eric Garcetti implemented a scoring system to [quantify cleanliness](https://www.citylab.com/solutions/2016/05/how-los-angeles-is-using-data-to-tackle-street-cleanliness/481722/) of city streets. How does your neighborhood stack up? Are you forced to hop over abandoned mattresses, or strolling down a sparkling sidewalk? To answer this question, we will look at cleanliness ratings for various neighborhoods in Los Angeles County. \n",
        "\n",
        "While programming experience helps for this instructable, it is not required.* (Please see our [first](https://colab.research.google.com/drive/1102rYgCZMWIPa0HdezbiiEx-t5Ikct0s#scrollTo=bu7i1hbHvGzW) and [second](https://colab.research.google.com/drive/1QKoElHpzqC0wf7T4oBFbZ4QQXgXRSXMr#scrollTo=w4D-Jd8tgvBQ) instructables for information on the tools used in this exercise, and the [final](https://colab.research.google.com/drive/1NyiS1KsojrsGxBSf5zxeil-M4R_ffD-2#scrollTo=l6t7XEUgDGZY) instructable for information on APIs)*\n",
        "\n",
        "# Step 1: Gather and Understand Ingredients Used in This Notebook\n",
        "\n",
        "In this instructable we'll be exploring another way to map geographic data: using the [shapefile format](http://desktop.arcgis.com/en/arcmap/10.3/manage-data/shapefiles/what-is-a-shapefile.htm) created by ESRI. Shapefiles are vector format files about geographic coordinates or polygons that are stored in a compressed zip file. Vector formats store information about graphics as mathematical formulas, rather than pixels, which makes the files small and portable. About 2127 entries on [LA Counts](http://lacounts.org/) feature shapefiles, making it one of the more popular formats. When you use shapefiles, Mapbox converts the data from the compressed zip file to vector tiles. From there, you can create styles using this geographic data to generate map visualizations, similar to the last Instructable, which mapped geographic coordinates. \n",
        "\n",
        "For this exercise, you will need: \n",
        "\n",
        "*  Download a Shapefile dataset from [LA Counts ](https://lacounts.org). In this exercise we will use a dataset for the [Clean Streets Index](https://www.lacounts.org/dataset/clean-streets-index-grids-2018-quarter-3) created by the city of Los Angeles. We selected this file becuase it was well-documented through metadata, and featured a Shapefile. \n",
        "*  A Jupyter Notebook like this one, hosted on [Google's colab.](http://colab.research.google.com/) \n",
        "*   Free Python Libraries (pyshp [link text](https://pypi.org/project/pyshp/\n",
        "), [numpy](http://www.numpy.org/), [pandas](https://pandas.pydata.org/), and [plotly](https://plot.ly/python/)), and [Mapbox](https://www.mapbox.com/). These are accessible within Jupyter Notebooks, so you don't need to download them. \n",
        "*   Your smarts! ð§  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkChoIAwLHrS"
      },
      "source": [
        "# Step 2: Upload Shapefile Data to Jupyter Notebook \n",
        "\n",
        "First, unzip your shapefile package that you downloaded from LA Counts. Next, upload all the files in the zip file to the Jupyter Notebook. Do this by: \n",
        "\n",
        "1. If necessary, click on the arrow in your upper-left corner to open the sidebar. \n",
        "\n",
        "![alt text](http://www.civictechs.com/wp-content/uploads/2019/06/step-1-arrow.png)\n",
        "\n",
        "2. Click on \"Files,\" then \"upload.\" \n",
        "\n",
        "![alt text](http://www.civictechs.com/wp-content/uploads/2019/06/steps-2-and-three.png)\n",
        "\n",
        "3. Select and upload your files. You should then see them appear in the file window. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JBKheg0xYIW"
      },
      "source": [
        "# Step 2: Configuration and Download Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb-_co3Mxk0Z"
      },
      "source": [
        "# First install missing Python packages\n",
        "\n",
        "print(\"Installing geopandas...\")\n",
        "\n",
        "# We need to install geopandas and descartes using PIP because they are \n",
        "# not installed on Jupyter by default. \n",
        "\n",
        "!pip install geopandas\n",
        "!pip install descartes \n",
        "\n",
        "!pip install geopy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-Qq6FQQ7o7l"
      },
      "source": [
        "# Python library to parse us addresses from text strings\n",
        "# https://github.com/datamade/usaddress\n",
        "\n",
        "!pip install usaddress"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYw6kRfS7rq6"
      },
      "source": [
        "# Start importing Python packages from core to special purpose with more dependencies\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTOlBtcvLS6o"
      },
      "source": [
        "import re\n",
        "import json\n",
        "from collections import OrderedDict "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBcll_mP71WE"
      },
      "source": [
        "import usaddress"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F67DxsjZUNDJ"
      },
      "source": [
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, Polygon\n",
        "\n",
        "import geopy\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "\n",
        "import folium\n",
        "from folium.plugins import FastMarkerCluster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5MYvkkwJ3ee"
      },
      "source": [
        "# Step 3: Load and Print The Shapefile  \n",
        "\n",
        "Next, load your shapefile and print it out. \n",
        "\n",
        "The Los Angeles Clean Streets Index is a grading system for every street in Los Angeles. The Bureau of Sanitation drove and scored over 9,000 miles of streets and alleys - each segment received a \"cleanliness score\" from 1-3. Each street score is based on four factors: litter (Seg_LL_Sco), weeds (Seg_Wd_Sco), bulky items (Seg_Bk_Sco), and illegal dumping (Seg_ID_Sco) that are aggregated into CSCatScore, a value that designates overall cleanliness. This assessment is repeated every quarter. This assessment is for Quarter 2 of 2018. Los Angeles is leading the way as the only big city in the US conducting a regular cleanliness assessment of every City street. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIA9aX_q3DQo"
      },
      "source": [
        "# Next, print out the shapefile. \n",
        "# It won't look like much because we are looking at geographic coordinates. \n",
        "\n",
        "print(\"Loading Shapefile...\")\n",
        "\n",
        "# If using your files, replace below filename (\"Clean_Streets_Index_Grids_2018_Quarter_3.shp\") with the \n",
        "# shapefile filename you uploaded. \n",
        "\n",
        "shapefile = gpd.read_file(\"vote_precincts.shp\")\n",
        "\n",
        "# The \"head\" function prints out the first five rows in full, so you can see\n",
        "# the columns in the data set too! \n",
        "\n",
        "shapefile.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vo-DOmeBM1K"
      },
      "source": [
        "# Step 4: Load Polling Data and Locations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEomIr7MRhkY"
      },
      "source": [
        "## Step 4. (a) Combine core data from every year into one consistent DataFrame knox_all_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40C1Yyw-PB0U"
      },
      "source": [
        "# TODO: clean up and standardize the column headers to be exactly the same across all tabs\n",
        "#       with no embedded spaces:\n",
        "# \n",
        "# instead of \"Registered R\" and \"R Registered\" use \"Registered_R\" everywhere"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGDRp3f-GIqC"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikSh8zWKG1MK"
      },
      "source": [
        "# CUSTOMIZE: Set this variable to the name of your Excel file with polling data\r\n",
        "\r\n",
        "knox_poll_data_xls = 'knox_co_oh_polling_2006-2012_20201210.xls'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhQqqu9RPZ8T"
      },
      "source": [
        "# Read the sheet named '2006_addr' which has address string in column 'addresses'\n",
        "\n",
        "# knox2006_df = pd.read_excel(url_file, sheet_name='2006', names=['precinct', 'reg_total', 'reg_dem', 'reg_rep'])\n",
        "knox2006_df = pd.read_excel(knox_poll_data_xls, sheet_name='2006', names=['precinct', 'reg_total', 'reg_dem', 'reg_rep'])\n",
        "\n",
        "knox2006_df['year'] = '2006'\n",
        "knox2006_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaMk74-xQABl"
      },
      "source": [
        "# Read the sheet named '2008_addr' which has address string in column 'addresses'\n",
        "\n",
        "# knox2008_df = pd.read_excel(url_file, sheet_name='2008', names=['precinct', 'reg_total', 'reg_dem', 'reg_rep'])\n",
        "knox2008_df = pd.read_excel(knox_poll_data_xls, sheet_name='2008', names=['precinct', 'reg_total', 'reg_dem', 'reg_rep'])\n",
        "knox2008_df['year'] = '2008'\n",
        "\n",
        "knox2008_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg2wS3r5QqDL"
      },
      "source": [
        "# Read the sheet named '2010_addr' which has address string in column 'addresses'\n",
        "\n",
        "# knox2010_df = pd.read_excel(url_file, sheet_name='2010', names=['precinct', 'reg_total', 'reg_dem', 'reg_rep'])\n",
        "knox2010_df = pd.read_excel(knox_poll_data_xls, sheet_name='2010', names=['precinct', 'reg_total', 'reg_dem', 'reg_rep'])\n",
        "knox2010_df['year'] = '2010'\n",
        "\n",
        "knox2010_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TpqHqTvyDSq"
      },
      "source": [
        "# Read the sheet named '2012_addr' which has address string in column 'addresses'\n",
        "\n",
        "# knox2012_df = pd.read_excel(url_file, sheet_name='2012', names=['precinct', 'reg_total', 'reg_dem', 'reg_rep'])\n",
        "knox2012_df = pd.read_excel(knox_poll_data_xls, sheet_name='2012', names=['precinct', 'reg_total', 'reg_dem', 'reg_rep'])\n",
        "knox2012_df['year'] = '2012'\n",
        "\n",
        "knox2012_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6-R5i4tP_2l"
      },
      "source": [
        "# Concatenate all polling data DataFrames into one master\n",
        "#\n",
        "# CHECK visually inspect for bad, missing or other malformed data (e.g. typos, outliners, impossible values)\n",
        "# if found, GOBACK to your source xls files and clean up!\n",
        "\n",
        "knox_dfs = [knox2006_df, knox2008_df, knox2010_df, knox2012_df]\n",
        "knox_2006_2012_df = pd.concat(knox_dfs)\n",
        "\n",
        "# Drop rows where 'precinct' is 'NaN' or some variant of 'Totals'\n",
        "knox_2006_2012_df = knox_2006_2012_df[knox_2006_2012_df['precinct'].str.strip().str.len() > 8]\n",
        "\n",
        "knox_2006_2012_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eopWJKAwcWp"
      },
      "source": [
        "knox_2006_2012_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDyhEpJ71FnR"
      },
      "source": [
        "# DO Clean your source xls datafile by adding missing 'reg_total' (Registered voters total has one blank cell)\n",
        "\n",
        "# Drop rows where 'precinct' is 'NaN' or some variant of 'Totals'\n",
        "# knox_2006_2012_df = knox_2006_2012_df[knox_2006_2012_df['reg_total'].notnull()] # astype(str).str.strip() != '']\n",
        "\n",
        "# Drop rows with 'NaN' entries\n",
        "knox_2006_2012_df = knox_2006_2012_df[knox_2006_2012_df.notnull()] # astype(str).str.strip() != '']\n",
        "\n",
        "\n",
        "knox_2006_2012_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5rLnjI-tcaC"
      },
      "source": [
        "# Split out the precinct string into precinct_no and precint_name\n",
        "\n",
        "knox_2006_2012_df['precinct_no'] = knox_2006_2012_df['precinct'].str.split(' ').str.get(0).astype(int)\n",
        "knox_2006_2012_df['precinct_name'] = knox_2006_2012_df['precinct'].str.split(' ').str[1:].str.join(' ').str.title()\n",
        "\n",
        "knox_2006_2012_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "knox_2006_2012_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEsX14hzIGmJ"
      },
      "source": [
        "# CLEAN: last row in dataset has 'NaN' for RegDem and RegRep\r\n",
        "#        go back and fix, for now we have to drop entire row for 0059 FREDERICKTOWN C\r\n",
        "\r\n",
        "knox_2006_2012_df = knox_2006_2012_df.dropna()\r\n",
        "knox_2006_2012_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3I2-Epz6c3U"
      },
      "source": [
        "# Assign more narrow/accurate types for robustness and better error detection\n",
        "\n",
        "knox_2006_2012_df['precinct'] = knox_2006_2012_df['precinct'].astype('string')\n",
        "knox_2006_2012_df['reg_total'] = knox_2006_2012_df['reg_total'].astype('int')\n",
        "knox_2006_2012_df['reg_dem'] = knox_2006_2012_df['reg_dem'].astype('int')\n",
        "knox_2006_2012_df['reg_rep'] = knox_2006_2012_df['reg_rep'].astype('int')\n",
        "knox_2006_2012_df['year'] = knox_2006_2012_df['year'].astype('int')\n",
        "knox_2006_2012_df['precinct_name'] = knox_2006_2012_df['precinct_name'].astype('string') \n",
        "knox_2006_2012_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d0TwZDUEFrw"
      },
      "source": [
        "# Rearrange column by importance\n",
        "\n",
        "knox_2006_2012_df = knox_2006_2012_df[['precinct_no', 'precinct_name', 'reg_total', 'reg_dem', 'reg_rep', 'year', 'precinct']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRf3fg8SPFFu"
      },
      "source": [
        "# CHECK for that we have no missing data by comparing Non-Null Count\n",
        "\n",
        "knox_2006_2012_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgOKREVAwpZc"
      },
      "source": [
        "# CHECK Visually inspect entire knox_2006_2012_df DataFrame to find \n",
        "# bad rows with missing data, make sure each change does not introduce errors/bad data\n",
        "\n",
        "knox_2006_2012_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULbZfXNN637n"
      },
      "source": [
        "## Step 4. (b) Extract out sub-components from address string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPWwQs596KOv"
      },
      "source": [
        "# Parse address string into separate components/columns (incomplete, only exists for 2006 and even then has 5 empty addresses)\n",
        "#\n",
        "# NOTE: (Dataset profile) \n",
        "#\n",
        "# - 58 rows/polling sites with 5 blank '054 DANVILLE', '055 WAYNE', '056 FREDERICKTOWN A', '057 FREDERICKTOWN B', '058 FREDERICKTOWN C'\n",
        "# - row may be blank\n",
        "# - state = ['', 'OH', 'OHIO']\n",
        "# - city = ['MT. VERNON', 'MOUNT VERNON', 'FREDRICKTOWN', 'DANVILLE', 'HOWARD', 'GAMBIER', 'CENTERBERG', 'BLADENSBERG', 'GLENMONT', 'UTICA']\n",
        "# - address (ends with, with/without final '.') = ['ROAD', 'RD.', 'STREET', 'ST.', 'DRIVE', 'DR.', 'AVE.', 'LANE']\n",
        "# - address no. = [/d]{2,5} (2-5 digit integer)\n",
        "\n",
        "knox2006_addr_df = pd.read_excel(knox_poll_data_xls, sheet_name='2006_addr', names=['precinct', 'address', 'reg_total', 'reg_dem', 'reg_rep'], dtype={'address':str})\n",
        "knox2006_addr_df['year'] = '2006'\n",
        "\n",
        "knox2006_addr_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2MM3GpeJlUi"
      },
      "source": [
        "# BUG in Pandas\r\n",
        "\r\n",
        "type(knox2006_addr_df.iloc[6]['reg_total'])   # str (empty)\r\n",
        "# type(knox2006_addr_df.iloc[7]['reg_total']) # int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjnh81nWKxi0"
      },
      "source": [
        "test_str = 0\r\n",
        "print(isinstance(test_str, str))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlHAjxrBKYrD"
      },
      "source": [
        "# CLEAN: Previous cell show issing reg_total for 0007 MOUNT VERNON 2-C \r\n",
        "#        so drop row index=6\r\n",
        "\r\n",
        "knox2006_addr_df.drop(6, inplace=True)\r\n",
        "\r\n",
        "# index_reg_total = knox2006_addr_df.reg_total.apply(lambda x : isinstance(x, str))\r\n",
        "# print(index_reg_total)\r\n",
        "\r\n",
        "# knox2006_addr_df.drop(index_reg_total, inplace=True, axis=0)\r\n",
        "# index_names = (isinstance(knox2006_addr_df['reg_total'],str)) | (isinstance(knox2006_addr_df['reg_dem'],str)) | (isinstance(knox2006_addr_df['reg_rep'],str))\r\n",
        "# type(index_names)\r\n",
        "\r\n",
        "# drop these given row \r\n",
        "# indexes from dataFrame \r\n",
        "# df.drop(index_names, inplace = True, axis=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsXJ4iiCGfji"
      },
      "source": [
        "# CLEAN: Previous cell show the last 6 rows with 'NaN' so have to drop\n",
        "#        Go back and fix, for now we have to drop these rows\n",
        "#       \n",
        "# Drop rows where 'precinct' is 'NaN' or some variant of 'Totals'\n",
        "\n",
        "# knox2006_addr_df = knox2006_addr_df[knox2006_addr_df['precinct'].str.strip().str.len() > 8]\n",
        "knox2006_addr_df = knox2006_addr_df.dropna()\n",
        "knox2006_addr_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuAwTus0GEtc"
      },
      "source": [
        "# Split out the precinct string into precinct_no and precint_name\n",
        "\n",
        "knox2006_addr_df['precinct_no'] = knox2006_addr_df['precinct'].str.split(' ').str.get(0).astype(int)\n",
        "knox2006_addr_df['precinct_name'] = knox2006_addr_df['precinct'].str.split(' ').str[1:].str.join(' ').str.title()\n",
        "\n",
        "knox2006_addr_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "knox2006_addr_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXdcp41h7_kv"
      },
      "source": [
        "# Assign more narrow/accurate types for robustness and better error detection\n",
        "\n",
        "knox2006_addr_df['precinct'] = knox2006_addr_df['precinct'].astype('string')\n",
        "knox2006_addr_df['address'] = knox2006_addr_df['address'].astype('string') \n",
        "knox2006_addr_df['reg_total'] = knox2006_addr_df['reg_total'].astype('int')\n",
        "knox2006_addr_df['reg_dem'] = knox2006_addr_df['reg_dem'].astype('int')\n",
        "knox2006_addr_df['reg_rep'] = knox2006_addr_df['reg_rep'].astype('int')\n",
        "knox2006_addr_df['year'] = knox2006_addr_df['year'].astype('int')\n",
        "knox2006_addr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VQcYIyh98KL"
      },
      "source": [
        "# Drop rows where 'address' is 'NaN' or other issues\n",
        "# TODO Goback to original xls file and fix source of these errors\n",
        "\n",
        "knox2006_addr_df = knox2006_addr_df[pd.notnull(knox2006_addr_df['address'])]\n",
        "knox2006_addr_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAOObxr_-eMi"
      },
      "source": [
        "# TODO Visually inspect for errors, bad data, missing data, etc.\n",
        "#      then correct in source xls files (missing address for precincts >= 54 or indexes >= 53)\n",
        "\n",
        "knox2006_addr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdvZtE3skIIu"
      },
      "source": [
        "# DEBUGGING ONLY:\n",
        "# test cell: edge case with street name prefix ('StreetNamePreDirectional') variants and edge cases\n",
        "\n",
        "addr_err = '505 S YELLOW JACKET ST. DANVILLE, OHIO, 43014'\n",
        "\n",
        "try:\n",
        "    tagged_address, address_type = usaddress.tag(addr_err)\n",
        "except usaddress.RepeatedLabelError as e :\n",
        "    some_special_instructions(e.parsed_string, e.original_string)\n",
        "\n",
        "tagged_address"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MA5hY0623x8"
      },
      "source": [
        "# DEBUGGING ONLY:\n",
        "\n",
        "tagged_address['AddressNumber']\n",
        "tagged_address['StateName']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cKZDERo26ev"
      },
      "source": [
        "# DEBUGGING ONLY\n",
        "\n",
        "address_type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb6XgefJ_t0W"
      },
      "source": [
        "# DEBUGGING ONLY: \n",
        "# knox2006_addr_df.drop('addr_parsed', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFJxFPiz_b_X"
      },
      "source": [
        "knox2006_addr_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiunbvX158O0"
      },
      "source": [
        "knox2006_addr_df['addr_parsed'] = knox2006_addr_df.apply(lambda row: usaddress.parse(row['address']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMOCCf3FwL1a"
      },
      "source": [
        "knox2006_addr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtwkdmiMAH3a"
      },
      "source": [
        "# NOTE: addr_parsed is a pd.Series containing a list of tuples\n",
        "\n",
        "print(knox2006_addr_df['addr_parsed'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFlV60WuHILA"
      },
      "source": [
        "knox2006_addr_df = knox2006_addr_df[['precinct_no', 'precinct_name', 'address', 'reg_total', 'reg_dem', 'reg_rep' ,'year', 'addr_parsed', 'precinct']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuF8JBfZwk-H"
      },
      "source": [
        "knox2006_addr_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly3uabgRR--h"
      },
      "source": [
        "# CLEAN: Previous cell shows inconsistent format for 'address' which causes\r\n",
        "#        parse errors in cells below\r\n",
        "\r\n",
        "# FIX: Data in 'address' column of Excel notebook to be consisent\r\n",
        "#      e.g. first 2 precints above (Mount Vernon 1-A, 1-B) are malformed\r\n",
        "#      with missing street number or street number after instead of before street name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxSMoGDLQI4i"
      },
      "source": [
        "def split_addr(str):\r\n",
        "  try:\r\n",
        "    tagged_address, address_type = usaddress.tag(string)\r\n",
        "  except usaddress.RepeatedLabelError as e :\r\n",
        "    some_special_instructions(e.parsed_string, e.original_string)\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2deRCWhd9obP"
      },
      "source": [
        "# Create a temp working DataFrame addr_df to help parse address components\n",
        "\n",
        "addr_df = knox2006_addr_df.apply(lambda row: usaddress.tag(row['address']), axis=1)\n",
        "addr_df.head(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BDrXbkem03N"
      },
      "source": [
        "# In the following cells, create separate DataFrames for all parts of the address\n",
        "# These DataFrames will then be horizontally concatenated with the original DataFrame\n",
        "# so we can later extract clean text to make GeoPy REST API calls\n",
        "# to obtain (long, lat) values for each polling station"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDwsozkMFtX6"
      },
      "source": [
        "# TODO: convert these to def fn(df) to be able to handle multiple year datasets when\n",
        "#       they become available\n",
        "\n",
        "addr_parts_ls = []\n",
        "\n",
        "for num, row in enumerate(addr_df):\n",
        "  # print(f\"Working on row #: {num}\")\n",
        "\n",
        "  if 'Recipient' not in row[0]:\n",
        "    if ('AddressNumber' in row[0]) & ('StreetName' in row[0]) & ('StreetNamePostType' in row[0]):\n",
        "      if ('StreetNamePreDirectional' in row[0]):\n",
        "        FullAddress = ' '.join([row[0]['AddressNumber'].strip(), row[0]['StreetNamePreDirectional'].strip().title(), row[0]['StreetName'].strip().title(), row[0]['StreetNamePostType'].strip().title()])\n",
        "      else:\n",
        "        FullAddress = ' '.join([row[0]['AddressNumber'].strip(), row[0]['StreetName'].strip().title(), row[0]['StreetNamePostType'].strip().title()])\n",
        "    else:\n",
        "      FullAddress = ''\n",
        "  else:\n",
        "    # print('Record missing.')\n",
        "    FullAddress = ''\n",
        "  \n",
        "  addr_parts_ls.append(FullAddress)\n",
        "\n",
        "print(addr_parts_ls)\n",
        "# usaaddr = useaddress.tag(row['address'])\n",
        "# print(usaaddr['StreetName'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdujG1MUFtUh"
      },
      "source": [
        "city_parts_ls = []\n",
        "\n",
        "for num, row in enumerate(addr_df):\n",
        "  # print(f\"Working on row #: {num}\")\n",
        "\n",
        "  if 'Recipient' not in row[0]:\n",
        "    if 'PlaceName' in row[0]:\n",
        "      FullCity = row[0]['PlaceName'].strip().title()\n",
        "    else:\n",
        "      FullCity = ''\n",
        "  else:\n",
        "    # print('Record missing.')\n",
        "    FullCity = ''\n",
        "  \n",
        "  city_parts_ls.append(FullCity)\n",
        "\n",
        "print(city_parts_ls)\n",
        "  # usaaddr = useaddress.tag(row['address'])\n",
        "  # print(usaaddr['StreetName'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkZH3c5zFtRX"
      },
      "source": [
        "state_parts_ls = []\n",
        "\n",
        "for num, row in enumerate(addr_df):\n",
        "  # print(f\"Working on row #: {num}\")\n",
        "\n",
        "  if 'Recipient' not in row[0]:\n",
        "    if 'StateName' in row[0]:\n",
        "      FullState = row[0]['StateName'].strip().title()\n",
        "    else:\n",
        "      FullState = ''\n",
        "  else:\n",
        "    # print('Record missing.')\n",
        "    FullState = ''\n",
        "  \n",
        "  state_parts_ls.append(FullState)\n",
        "\n",
        "print(state_parts_ls)\n",
        "  # usaaddr = useaddress.tag(row['address'])\n",
        "  # print(usaaddr['StreetName'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zejlLuu3FtNI"
      },
      "source": [
        "zip_parts_ls = []\n",
        "\n",
        "for num, row in enumerate(addr_df):\n",
        "  # print(f\"Working on row #: {num}\")\n",
        "\n",
        "  if 'Recipient' not in row[0]:\n",
        "    if 'ZipCode' in row[0]:\n",
        "      FullZip = int(row[0]['ZipCode'].strip())\n",
        "    else:\n",
        "      FullZip = ''\n",
        "  else:\n",
        "    # print('Record missing.')\n",
        "    FullZip = ''\n",
        "  \n",
        "  zip_parts_ls.append(FullZip)\n",
        "\n",
        "print(zip_parts_ls)\n",
        "  # usaaddr = useaddress.tag(row['address'])\n",
        "  # print(usaaddr['StreetName'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7yCL7wuFWXh"
      },
      "source": [
        "addr_all_parts_df = pd.DataFrame(\n",
        "    {'addr_full': addr_parts_ls,\n",
        "     'city': city_parts_ls,\n",
        "     'state': state_parts_ls,\n",
        "     'zip': zip_parts_ls\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTljnRQfB97q"
      },
      "source": [
        "# Set defaults for Knox County Ohio, USA\n",
        "\n",
        "addr_all_parts_df['state'] = \"OH\"\n",
        "addr_all_parts_df['country'] = \"USA\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrBHHBFCA-ww"
      },
      "source": [
        "# Assign more narrow/accurate types for robustness and better error detection\n",
        "\n",
        "addr_all_parts_df['addr_full'] = addr_all_parts_df['addr_full'].astype('string')\n",
        "addr_all_parts_df['city'] = addr_all_parts_df['city'].astype('string') \n",
        "addr_all_parts_df['state'] = addr_all_parts_df['state'].astype('string')\n",
        "addr_all_parts_df['zip'] = addr_all_parts_df['zip'].astype('int')\n",
        "addr_all_parts_df['country'] = addr_all_parts_df['country'].astype('string')\n",
        "addr_all_parts_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzcOP11dL9MN"
      },
      "source": [
        "# knox_2006_addr_df will be our master DataFrame with all years concatenated together\n",
        "\n",
        "knox_2006_addr_df = pd.concat([knox2006_addr_df, addr_all_parts_df], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZpJM9OFFfRg"
      },
      "source": [
        "knox_2006_addr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xLl1c4hDJv0"
      },
      "source": [
        "# Reorder columns\n",
        "\n",
        "knox_2006_addr_df = knox_2006_addr_df[['precinct_no', 'precinct_name', 'address', 'addr_full', 'reg_total', 'reg_dem', 'reg_rep', 'year', 'city', 'state', 'zip', 'country', 'addr_parsed', 'precinct']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hvKY8FkDSPH"
      },
      "source": [
        "knox_2006_addr_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-8y3qO3CWoD"
      },
      "source": [
        "# Visually inspect for errors, missing, malformed, etc data\n",
        "\n",
        "knox_2006_addr_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vSEU1CCR_Ky"
      },
      "source": [
        "## Step 4. (c) Calculate new column values for each (Polling Station + Year) data point\n",
        "\n",
        "Current Over/Under Served Polling areas\n",
        "* %Knox Co Reg Voters = (Poll Station Registered Voters)/(Total Reg Voters in Knox Co)\n",
        "* %Democrat = (Poll Station Registered Democrats)/(Poll Station Registered Republicans + Poll Station Registered Republicans)\n",
        "* %Republican = (Poll Station Registered Republicans)/(Poll Station Registered Republicans + Poll Station Registered Republicans)\n",
        "\n",
        "Trends over Time\n",
        "* %Democrat Growth = (2012 Reg Dem - 2006 Reg Dem)/(2006 Reg Dem)\n",
        "* %Republican Growth = (2012 Reg Rep - 2006 Reg Rep)/(2006 Reg Rep)\n",
        "\n",
        "Use Seaborn graphs to represent 3 additional dimensions of data:\n",
        "* Color = Republican (Red) or Democrat (Blue) - Hue reflect % dominance\n",
        "* Size = Relative number of registered voters\n",
        "* Shape = UP (Growing) or Down (Shrinking) number of registered voters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaWTa9ycOJ39"
      },
      "source": [
        "knox_2006_2012_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f17i01SIEni"
      },
      "source": [
        "knox_2006_2012_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dyb3rdvOJ0d"
      },
      "source": [
        "# ERROR: Need to recalc these broken out by each year, not over all 4 years\n",
        "\n",
        "knox_2006_2012_df['per_knox'] = knox_2006_2012_df['reg_total']/knox_2006_2012_df['reg_total'].sum() * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HJFKZOGOJw8"
      },
      "source": [
        "# ERROR: Need to recalc these broken out by each year, not over all 4 years\n",
        "\n",
        "knox_2006_2012_df['per_dem'] = knox_2006_2012_df['reg_dem']/knox_2006_2012_df['reg_total']\n",
        "knox_2006_2012_df['per_rep'] = knox_2006_2012_df['reg_rep']/knox_2006_2012_df['reg_total']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQW-LxwnIOtp"
      },
      "source": [
        "knox_2006_2012_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR4PEo8hIRie"
      },
      "source": [
        "knox_2006_2012_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONDE7LbQIU4q"
      },
      "source": [
        "# ERROR: Need to recalc these broken out by each year, not over all 4 years\n",
        "\n",
        "# Check math\n",
        "\n",
        "print(knox_2006_2012_df['per_knox'].sum())\n",
        "print(knox_2006_2012_df['per_dem'].sum())\n",
        "print(knox_2006_2012_df['per_rep'].sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2hdi8aSPHkt"
      },
      "source": [
        "knox2012_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0Lm_jqqjUST"
      },
      "source": [
        "%whos\n",
        "# Show all the variable defined in the current environment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW0eq-O5PHee"
      },
      "source": [
        "# Calculate the change in Knox Co. registered voters between 2006 and 2012\n",
        "\n",
        "knox_2006_2012_df['incr_voters_since_2006'] = knox2012_df['reg_total'] - knox2006_addr_df['reg_total']\n",
        "\n",
        "knox_2006_2012_df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49aLqrm6PHaq"
      },
      "source": [
        "# Calculate the numerical change in Knox Co registered voters by party affiliation 2006 to 2012\n",
        "\n",
        "knox_2006_2012_df['incr_dem_since_2006'] = knox2012_df['reg_dem'] - knox2006_addr_df['reg_dem']\n",
        "knox_2006_2012_df['incr_rep_since_2006'] = knox2012_df['reg_rep'] - knox2006_addr_df['reg_rep']\n",
        "knox_2006_2012_df['incr_3rd_since_2006'] = (knox2012_df['reg_total'] - knox2012_df['reg_dem'] - knox2012_df['reg_rep']) - (knox2006_addr_df['reg_total'] - knox2006_addr_df['reg_dem'] - knox2006_addr_df['reg_rep'])\n",
        "\n",
        "knox_2006_2012_df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkMFjPu0k583"
      },
      "source": [
        "# Calculate the percent change in Knox Co registered voters by party affiliation 2006 to 2012\n",
        "\n",
        "knox_2006_2012_df['per_incr_dem_since_2006'] = knox_2006_2012_df['incr_dem_since_2006']/knox2006_addr_df['reg_dem']\n",
        "knox_2006_2012_df['per_incr_rep_since_2006'] = knox_2006_2012_df['incr_rep_since_2006']/knox2006_addr_df['reg_rep']\n",
        "knox_2006_2012_df['per_incr_3rd_since_2006'] = knox_2006_2012_df['incr_3rd_since_2006']/(knox2006_addr_df['reg_total'] - knox2006_addr_df['reg_dem'] - knox2006_addr_df['reg_rep'])\n",
        "\n",
        "knox2012_df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBnRyiCSoUq9"
      },
      "source": [
        "knox_2006_2012_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2svmDK9mAdX"
      },
      "source": [
        "# Drop rows where 'precinct' is 'NaN' or some variant of 'Totals'\n",
        "\n",
        "knox2006_addr_df = knox2006_addr_df[knox2006_addr_df['precinct'].str.strip().str.len() > 8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXxtH1KEmRfp"
      },
      "source": [
        "# Split out the precinct string into precinct_no and precint_name\n",
        "\n",
        "knox2006_addr_df['precinct_no'] = knox2006_addr_df['precinct'].str.split(' ').str.get(0).astype(int)\n",
        "knox2006_addr_df['precinct_name'] = knox2006_addr_df['precinct'].str.split(' ').str[1:].str.join(' ').str.title()\n",
        "\n",
        "knox2006_addr_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "knox2006_addr_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spfbZuWCnWzL"
      },
      "source": [
        "# Visually inspect and look for non_dull\n",
        "\n",
        "knox2012_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPJbjy8cnG3R"
      },
      "source": [
        "# DO Clean your source xls datafile by adding missing 'reg_total', 'reg_dem' (Registered voters total has one blank cell)\n",
        "\n",
        "# Drop rows where 'precinct' is 'NaN' or some variant of 'Totals'\n",
        "knox2012_df = knox2012_df[knox2012_df['reg_total'].notnull()] # astype(str).str.strip() != '']\n",
        "knox2012_df = knox2012_df[knox2012_df['dem_total'].notnull()] # astype(str).str.strip() != '']\n",
        "\n",
        "knox2012_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNc8vn8UmvBV"
      },
      "source": [
        "# Assign more narrow/accurate types for robustness and better error detection\n",
        "\n",
        "knox2012_df['precinct'] = knox2012_df['precinct'].astype('string')\n",
        "knox2012_df['reg_total'] = knox2012_df['reg_total'].astype('int')\n",
        "knox2012_df['reg_dem'] = knox2012_df['reg_dem'].astype('int')\n",
        "knox2012_df['reg_rep'] = knox2012_df['reg_rep'].astype('int')\n",
        "knox2012_df['year'] = knox2012_df['year'].astype('int')\n",
        "knox2012_df['precinct_name'] = knox2012_df['precinct_name'].astype('string') \n",
        "knox2012_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzcn022qBoI5"
      },
      "source": [
        "# Use Seaborn to graph Trends over Time\n",
        "\n",
        "# Reference: https://seaborn.pydata.org/generated/seaborn.lineplot.html\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4sL8QV8Q_ej"
      },
      "source": [
        "sns.set_style(\"darkgrid\")\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.title(\"Growth in Voter Registration by Polling Station (2006-2012)\")\n",
        "\n",
        "plot=sns.barplot(x='precinct', y='incr_voters_since_2006', data=knox2012_df)\n",
        "plt.setp(plot.get_xticklabels(), rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hJqhIenSxZq"
      },
      "source": [
        "sns.set_style(\"darkgrid\")\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.title(\"Growth in Democratic Registration by Polling Station (2006-2012)\")\n",
        "\n",
        "plot=sns.barplot(x='precinct', y='incr_dem_since_2006', data=knox2012_df)\n",
        "plt.setp(plot.get_xticklabels(), rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DAgiAP1SxRH"
      },
      "source": [
        "sns.set_style(\"darkgrid\")\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.title(\"Growth in Republican Registration by Polling Station (2006-2012)\")\n",
        "\n",
        "plot=sns.barplot(x='precinct', y='incr_rep_since_2006', data=knox2012_df)\n",
        "plt.setp(plot.get_xticklabels(), rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcYtpRmSVmoU"
      },
      "source": [
        "## Step 4. (d) Use GeoPandas to derive (long, lat) tuples for each physical address\n",
        "\n",
        "Github---\n",
        "* https://github.com/shakasom/geocoding\n",
        "\n",
        "Jupyter--\n",
        "* https://github.com/shakasom/geocoding/blob/master/ReverseGeocoding.ipynb\n",
        "\n",
        "Tutorial--\n",
        "* https://towardsdatascience.com/geocode-with-python-161ec1e62b89"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEFsh83MBoCs"
      },
      "source": [
        "locator = Nominatim(user_agent=\"myGeocoder\")\n",
        "location = locator.geocode(\"Champ de Mars, Paris, France\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCALb1NoBn_7"
      },
      "source": [
        "print(\"Latitude = {}, Longitude = {}\".format(location.latitude, location.longitude))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZqgNtU8fGyd"
      },
      "source": [
        "addr_str = '23400 NEWCASTLE ROAD GAMBIER OH, 43022 USA'\n",
        "addr_str2 = '505 S Market St, Danville, OH, 43014'\n",
        "addr_str3 = '20517 OLD MANSFIELD ROAD FREDERICKTOWN OHIO, 43019, USA'\n",
        "addr_str4 = '20517 Old Mansfield Road Fredericktown OH 43019 USA'\n",
        "addr_str5 = '505 MARKET ST. DANVILLE, OHIO, 43014'\n",
        "\n",
        "location = locator.geocode(addr_str2)\n",
        "print(\"Latitude = {}, Longitude = {}\".format(location.latitude, location.longitude))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6zh8NAdWqrK"
      },
      "source": [
        "knox2006_addr_map_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuMowqOSWYYl"
      },
      "source": [
        "if ('addr_full' in knox2006_addr_map_df) & ('city' in knox2006_addr_map_df) & ('state' in knox2006_addr_map_df) & ('zip' in knox2006_addr_map_df) & ('country' in knox2006_addr_map_df):\n",
        "  knox2006_addr_map_df['addr_geopy'] = knox2006_addr_map_df['addr_full'] +', '+ knox2006_addr_map_df['city'] +', '+ knox2006_addr_map_df['state'] +', '+ knox2006_addr_map_df['zip'].apply(str) +', '+ knox2006_addr_map_df['country']\n",
        "else:\n",
        "  print(\"Empty row\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-x4u1QwUpUw"
      },
      "source": [
        "knox2006_addr_map_df['addr_geopy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcaUsxkUBn9K"
      },
      "source": [
        "%%time\n",
        "\n",
        "geocode = RateLimiter(locator.geocode, min_delay_seconds=1)\n",
        "\n",
        "knox2006_addr_map_df['location'] = knox2006_addr_map_df['addr_geopy'].apply(geocode)\n",
        "knox2006_addr_map_df['point'] = knox2006_addr_map_df['location'].apply(lambda loc: tuple(loc.point) if loc else None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY0DwpRNetYu"
      },
      "source": [
        "knox2006_addr_map_df.head(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnyF5MotBTVu"
      },
      "source": [
        "knox2006_addr_map_df # tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ab1Gzx-BTQz"
      },
      "source": [
        "knox2006_addr_map_df['location']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InQKSlAwZt9S"
      },
      "source": [
        "print(knox2006_addr_map_df['point'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXjYiLHXc9w1"
      },
      "source": [
        "%%time\n",
        "\n",
        "# from geopy.geocoders import Nominatim\n",
        "\n",
        "# df=pd.DataFrame({'Address':['9 RUE DU FOSSE, L-7772, luxembourg', '37 RUE DE LA GARE,L-7535, luxembourg']})         \n",
        "knox2006_addr_map_df['Latitude'] = ''\n",
        "knox2006_addr_map_df['Longitude'] = ''\n",
        "locator = Nominatim(user_agent=\"myGeocoder\")\n",
        "for i in range(len(knox2006_addr_map_df)):\n",
        "  if len(knox2006_addr_map_df['addr_geopy']) > 10:\n",
        "    location = locator.geocode(knox2006_addr_map_df.loc[i,'addr_geopy'])\n",
        "    knox2006_addr_map_df.loc[i,'Latitude'] = location.latitude   \n",
        "    knox2006_addr_map_df.loc[i,'Longitude'] = location.longitude\n",
        "  else:\n",
        "    knox2006_addr_map_df.loc[i,'Latitude'] = ''   \n",
        "    knox2006_addr_map_df.loc[i,'Longitude'] = ''\n",
        "print(knox2006_addr_map_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LId-feVLBTMT"
      },
      "source": [
        "# split point column into latitude, longitude and altitude columns\n",
        "knox2006_addr_map_df[['latitude', 'longitude', 'altitude']] = knox2006_addr_map_df['point'].apply(unpack)\n",
        "knox2006_addr_map_df.head()\n",
        "\n",
        "\n",
        "unpackdf=pd.DataFrame(df.apply(lambda x : tuple_unpack(x.col_1,x.col_2),1).tolist(),columns=['col1','col2'],index=df.index)\n",
        "yourdf=pd.concat([unpackdf,df],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UYqZNylZO-U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqZ09qEKZO14"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyDNHo2LZOzF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntl7L0KqVOXz"
      },
      "source": [
        "# Step 5: Display Trends over Time with Seaborn/Plotly\n",
        "\n",
        "Use lineplots to show the relative growth/decline in both \n",
        "* (a) overall voter registration\n",
        "* (b) Dem vs Rep voter registration\n",
        "* (c) voter registration broken out by polling station \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRUKD3O5WY_2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-R4P_VaAi8i"
      },
      "source": [
        "# Step 6: Display the Shapefile Data as a Map\n",
        "\n",
        "Finally, display your shapefile data as a map. The polygons above will be rendered as they appear on the map of Los Angeles County. Yellow polygons designate neighborhoods that receive high (bad) scores on the four criteria: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU5DM2XUXH5v"
      },
      "source": [
        "shapefile.plot(column='State_Code', figsize=(16,8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McNQph-YWoLf"
      },
      "source": [
        "# Add pushpins to map according to\n",
        "#\n",
        "# (a) location (lat, long) coordinates\n",
        "# (b) shape [up/down] dep on growth trends\n",
        "# (c) size [big/small] dep on degree of growth\n",
        "# (d) color [Red - white - Blue] dep on % of [Rep - Non R/D - Dem]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnjgnDJbmx2_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgx9uEwwmxvd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssUPJEKtOgwI"
      },
      "source": [
        "# Step 7: Analyze\n",
        "\n",
        "* Why are these regions scoring low on cleanliness? \n",
        "* Are they densely populated areas, or are calls for bulky item pickups going unresponded to? \n",
        "* You could use the sub-variables - litter (Seg_LL_Sco), weeds (Seg_Wd_Sco), bulky items (Seg_Bk_Sco), and illegal dumping (Seg_ID_Sco) - to calculate your own aggregate score to map. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwFKLD7slhqh"
      },
      "source": [
        "# Step 8: What next?\n",
        "\n",
        "Congratulations, you just learned how to load and display shapefiles! In fact, you created a graphic with a fancy name, a Choropleth â a map where the color of each shape is based on the value of an associated variable! Here are some things you might do next: \n",
        "\n",
        "* Are you interested to make this map more interactive, or [adding a legend](http://geopandas.org/mapping.html#creating-a-legend) to your map? \n",
        "\n",
        "Have fun with your data analysis, and come back for the [next instructable](https://colab.research.google.com/drive/1Fuo0mHo9U_FMGp8BArGJKTxu75f1joWv#scrollTo=WlbDYtGBkFFi)! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx08h5v1OYuK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}